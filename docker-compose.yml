version: '3.8'

services:
  text-embeddings-inference:
    container_name: text-embeddings-inference-${PROJECT_NAME}
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-0.6
    command: --model-id ${MODEL_ID}  --pooling ${POOLING}
    ports:
      - "${PUBLIC_PORT}:80"
    volumes:
      - ./data:/data
    pull_policy: always
